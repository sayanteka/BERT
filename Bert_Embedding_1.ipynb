{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQxxnSTg2kGq",
        "outputId": "f450dd1d-d297-4049-a78b-110093788420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "6gRjB5RZ2-OP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
        "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')"
      ],
      "metadata": {
        "id": "XjUKxoQD3gH5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"hello world what a time to be alive!\"\n",
        "tokens = tokenizer.encode_plus(text, max_length=512,\n",
        "                               truncation=True, padding='max_length',\n",
        "                               return_tensors='pt')"
      ],
      "metadata": {
        "id": "qCE8TrXA31wh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input IDs for CLS token is 101.\n",
        "\n",
        "Input IDs for SEP token is 102.\n",
        "\n",
        "Input IDs PAD Token is 0"
      ],
      "metadata": {
        "id": "EsBd98EI4Z36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have input ids and segment ids.\n",
        "segment ids also known as attention mask.\n",
        "\n",
        "This tensor indicates which tokens should be attended to (value of 1) and which should be ignored (value of 0) during processing.\n",
        "\n",
        "[pad] tokens are set as"
      ],
      "metadata": {
        "id": "o0n15Rb-6qYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGEzl2H9389I",
        "outputId": "175ce47c-1eca-47b5-fa05-33c718df1903"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 7592, 2088, 2054, 1037, 2051, 2000, 2022, 4142,  999,  102,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"hello world what a time to be alive. My name is sayanteka\"\n",
        "tokens_new = tokenizer.encode_plus(text, max_length=512,\n",
        "                               truncation=True, padding='max_length',\n",
        "                               return_tensors='pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "kjIxQ-2h42yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIa-ZBMV5JHt",
        "outputId": "32cd79ad-2db3-4ece-9e85-81e832b3718a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  7592,  2088,  2054,  1037,  2051,  2000,  2022,  4142,  1012,\n",
              "          2026,  2171,  2003,  2360, 12956,  2912,   102,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**tokens)\n",
        "outputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tih-wV4V_7C7",
        "outputId": "6009f915-d12d-44a2-9d1a-e436ab31bfcf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The dense vector representations of our text contained within 'last_hidden_state' tensor\n",
        "embeddings = outputs.last_hidden_state\n",
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEfwvZ9hAKWI",
        "outputId": "0f780b5d-9823-481b-89a7-c021a0eb3b7d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3068, -0.0788,  1.7431,  ..., -0.0253, -0.1108,  0.0483],\n",
              "         [ 0.7130,  0.1044,  1.8346,  ...,  0.1134, -0.0756,  0.1267],\n",
              "         [ 0.8172,  0.1132,  1.5408,  ..., -0.3807,  0.0875, -0.1902],\n",
              "         ...,\n",
              "         [ 0.5351, -0.2527,  0.9820,  ..., -0.0215, -0.3696,  0.2446],\n",
              "         [ 0.4957, -0.3423,  0.9106,  ..., -0.0352, -0.3554,  0.1440],\n",
              "         [ 0.4143, -0.0859,  1.1123,  ...,  0.0122, -0.1843, -0.1364]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg174GaEA4Dn",
        "outputId": "7007f029-5380-48a7-df7c-de1813d0b626"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Embedding=Single vector encoding i.e. 512*768 will be changed to 768 in case of sentence embedding.\n",
        "\n",
        "This is done using mean pool operation.\n",
        "\n",
        "To do this mean pooling operation we will need to multiply each value in our embeddings tensor by it's respective attention_mask value - so that we ignore non-real tokens.\n",
        "\n",
        "Attention mask value is our segment ids\n"
      ],
      "metadata": {
        "id": "TghOdcakCCRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask = tokens['attention_mask']  #segment ids\n",
        "attention_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMw5UQyYA7je",
        "outputId": "d89ba04d-a479-47ac-f702-5e25c1dbee22"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask.unsqueeze(-1).shape #at -1 position 1 is added. if (-2) then it would have been [1,1,512]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTW6nQ6wDn1Q",
        "outputId": "43a21909-87b6-4fc5-ed81-88289d69bcff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
        "mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGYsoGgbELNE",
        "outputId": "b3c3833e-6480-46a5-b5a0-94c4e4fc3f77"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y1uEZZVE1a9",
        "outputId": "dea8add1-73d3-4935-f4ff-41af834a2d60"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-rT-2u2E8BW",
        "outputId": "5f76c509-ddfe-4a34-83cd-6fa04a6ddb64"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lfAY1RXFJlk",
        "outputId": "54e9d50f-2b6c-436d-e7fa-a9cc8f521b85"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QqJOVj5Fp-6",
        "outputId": "758725c1-d343-4560-e968-3f9886775489"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLPCbrefFsC1",
        "outputId": "24cf97e7-c3ec-4be3-a7f5-e78464f5c634"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[0][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCz8OSSFGekl",
        "outputId": "9da66f92-2596-4396-a3e9-18848ba984fb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(mask[0][0]), len(mask[0]), len(mask)\n",
        "#mask=1 batch=1 sntence\n",
        "#mask[0]=512 tokens in 1 sentence where real tokens are 1 non real are 0\n",
        "#mask[0][0]= since it is expanded for pooling operation where it is 1, it has been repeated 1 1 1 till 768 times for 1st token, similarly for 2nd token and so on"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhzJK4CyFXLd",
        "outputId": "a68b340c-51ec-46c7-c19e-857ca6307247"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 512, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_embeddings = embeddings * mask\n",
        "masked_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY7vFByXGri-",
        "outputId": "870bbadd-0821-4feb-edf7-5d37645b73b2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_embeddings\n",
        "\n",
        "#in embeddings for non real tokens was not zero but in masked embeddings it is zero"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi2aEaP2GzOl",
        "outputId": "8e6a994c-390f-4661-c258-fbf110a6a452"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3068, -0.0788,  1.7431,  ..., -0.0253, -0.1108,  0.0483],\n",
              "         [ 0.7130,  0.1044,  1.8346,  ...,  0.1134, -0.0756,  0.1267],\n",
              "         [ 0.8172,  0.1132,  1.5408,  ..., -0.3807,  0.0875, -0.1902],\n",
              "         ...,\n",
              "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
              "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
              "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summed = torch.sum(masked_embeddings, 1) #summation along axis 1 so 512 removed (horizantally from left to right)\n",
        "summed.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3UvGkMMG3Yp",
        "outputId": "9c2845d7-dd53-4ef8-9506-4b3e85fae205"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summed_mask = torch.clamp(mask.sum(1), min=1e-9) #In mask  while summing min has beeen added in order to replace 0 by 1e-9 so that division by zero doesn't occur\n",
        "summed_mask.shape\n",
        "\n",
        "#Then sum the number of values that must be given attention in each position of the tensor along axis=1 so 512 removed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f1D_il4Hfl3",
        "outputId": "5f56aa74-fd04-4480-af66-cd9afee1fa70"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_pooled = summed / summed_mask"
      ],
      "metadata": {
        "id": "wOEbaBu5IuFk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_pooled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCaK-ax8JVcD",
        "outputId": "b2f2e5c2-8e44-4285-a00c-ca1a524b2edb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_pooled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5ARGH2PJYi_",
        "outputId": "677f848f-63ac-4579-b700-4f744da6dad8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.4371e-01, -1.6712e-01,  1.6938e+00,  1.0773e-01,  3.9651e-01,\n",
              "         -1.0034e-01, -4.7002e-02,  7.9962e-01,  9.9557e-02, -9.4254e-01,\n",
              "         -2.3453e-01, -2.0168e-02,  1.9673e-01,  3.9952e-01,  1.1500e-01,\n",
              "          3.4273e-01, -6.4042e-01, -5.6996e-01,  2.7601e-01, -6.6139e-01,\n",
              "         -7.0416e-01, -2.9305e-01, -1.5104e-01, -2.2795e-01,  9.0203e-01,\n",
              "         -5.3868e-01, -1.0533e-01, -6.9518e-01, -3.7914e-01,  2.6069e-01,\n",
              "         -8.8313e-01, -1.1394e-01,  1.0662e+00, -5.9388e-01, -4.5752e-01,\n",
              "          1.4677e+00, -6.4333e-01, -1.7422e-01,  1.2722e-01, -4.2277e-01,\n",
              "          6.6559e-01, -1.9796e-01,  1.1205e+00,  2.3012e-01, -1.3350e+00,\n",
              "          4.1537e-01, -5.1203e-01,  4.1024e-01,  2.7452e-01, -8.5214e-01,\n",
              "          1.2710e-01, -8.0763e-01, -6.3740e-01, -3.1229e-01, -4.9854e-01,\n",
              "          3.2761e-01,  3.9804e-01, -4.4230e-01, -8.0382e-02,  4.9029e-01,\n",
              "          6.1305e-01, -5.9101e-01,  5.5611e-01,  1.7230e-01, -1.0206e+00,\n",
              "          1.7572e-01,  1.0949e+00, -3.6538e-01,  1.7774e-01,  4.3270e-01,\n",
              "          1.0963e+00, -8.3898e-02, -2.6611e-01,  4.0809e-01, -1.3963e+00,\n",
              "         -8.0904e-01,  1.9847e-01,  3.2139e-01,  4.0050e-01,  9.5752e-01,\n",
              "          9.1508e-01, -5.3994e-01,  1.0592e+00,  9.7352e-01, -6.0041e-01,\n",
              "          2.1563e-01,  1.3225e-01,  8.6221e-02, -2.0152e+00,  6.4119e-01,\n",
              "         -6.9878e-02, -7.2408e-01,  1.1759e+00,  1.8488e-01,  3.4277e-01,\n",
              "          6.5096e-01, -3.9148e-02, -6.0620e-01, -5.0671e-01, -3.2001e-01,\n",
              "          2.9667e-02, -2.2884e-01, -2.4417e-01,  5.7870e-02,  3.7981e-01,\n",
              "          4.9694e-01, -6.0655e-02, -1.2346e+00,  6.1337e-01,  9.5490e-02,\n",
              "          8.8232e-01,  4.7993e-02,  7.6415e-02,  6.4590e-01,  5.0325e-01,\n",
              "         -8.7077e-02, -1.4783e+00,  2.9612e-01,  4.6578e-02,  1.7338e-01,\n",
              "         -4.9755e-01,  6.4269e-01, -1.5406e-01, -5.6126e-01,  2.0604e-01,\n",
              "         -5.6562e-01, -8.1897e-02,  1.3078e-01, -5.5340e-01, -6.7645e-02,\n",
              "         -1.3948e-01,  7.0307e-01,  4.4462e-01, -1.0322e+00,  8.4083e-02,\n",
              "          8.6769e-01, -2.0125e-01, -7.3381e-01, -1.0247e+00, -2.0466e-01,\n",
              "         -6.3981e-01,  3.8276e-01,  3.9684e-01,  4.6901e-01,  1.4168e-01,\n",
              "         -5.7647e-01,  2.1898e-01, -2.2738e-01, -8.3409e-03, -2.4746e-01,\n",
              "         -9.9057e-01, -3.0005e-01, -8.8709e-01, -9.2324e-01, -4.6641e-01,\n",
              "         -3.9903e-01, -1.1783e+00,  5.3981e-01,  2.1995e-01,  4.0774e-01,\n",
              "         -3.7131e-01,  1.2338e+00, -1.9069e-01,  2.0049e-01, -1.1310e-01,\n",
              "         -1.5072e-01,  1.2708e+00,  1.0951e+00,  1.4560e-01,  3.6235e-01,\n",
              "          6.5676e-01, -3.4773e-01,  1.7364e-01,  1.1239e+00, -6.8744e-01,\n",
              "         -2.6254e-01,  1.7511e+00,  6.2811e-01,  4.7067e-01, -4.5984e-01,\n",
              "          5.2457e-01, -4.5056e-01,  5.5844e-01, -4.0008e-02,  4.4210e-02,\n",
              "         -1.2678e+00,  2.3521e-01, -2.9582e-01,  9.0942e-01,  1.8530e-01,\n",
              "          1.5625e-01, -1.9385e-01,  1.1832e-01, -1.4211e+00, -7.4084e-01,\n",
              "         -1.2756e-01,  1.9533e-01,  8.3617e-01, -1.9950e-01, -2.5804e-01,\n",
              "          5.3352e-01,  6.2741e-03,  9.5528e-01, -3.0540e-01,  1.2990e+00,\n",
              "          1.0194e+00,  1.3714e-01, -1.2520e-01, -3.0013e-01, -6.1435e-01,\n",
              "         -3.1806e-01,  1.1757e+00,  6.5084e-01, -1.7192e-01, -7.3129e-02,\n",
              "         -5.0328e-01,  7.4073e-01, -3.1717e-01, -1.0501e+00, -2.4812e-01,\n",
              "          5.9124e-01,  4.1397e-01,  1.5154e-02, -2.5077e-01,  3.3859e-01,\n",
              "          6.9724e-01,  7.8416e-01, -1.0414e+00, -1.2615e-01, -6.9690e-01,\n",
              "          1.7303e-01, -3.2313e-01,  2.3371e-02,  1.4733e+00,  6.4430e-01,\n",
              "          7.0171e-01,  1.0446e-01, -7.5574e-02,  5.6683e-01,  1.6810e-01,\n",
              "          1.9664e-01,  7.8176e-01,  9.6536e-02, -3.0505e-01, -1.1925e+00,\n",
              "         -6.0975e-01,  1.0143e+00,  1.1556e-01, -1.1024e+00,  3.5646e-01,\n",
              "         -2.8990e-01, -8.0156e-01, -4.2614e-01,  2.9002e-01, -2.7425e-01,\n",
              "         -3.9380e-01, -1.6371e+00, -3.6250e-01, -2.7436e-01, -4.3914e-01,\n",
              "          3.5285e-01, -7.9173e-01, -9.2452e-02, -1.9320e-01, -8.5891e-01,\n",
              "          1.9185e-02, -3.0863e-01, -4.3679e-01, -1.1833e-01,  3.6784e-01,\n",
              "         -5.3335e-01,  7.9402e-01, -5.2792e-02,  5.6997e-01,  7.6599e-01,\n",
              "         -2.6063e-01,  8.5726e-01,  1.2974e-01, -1.7000e-01,  2.4458e-01,\n",
              "         -2.8240e-01,  1.9680e-01, -2.4120e+00, -7.4284e-01, -6.5134e-02,\n",
              "         -2.5929e-01,  7.3756e-01, -4.7114e-01, -3.0464e-01, -4.5057e-01,\n",
              "         -4.4889e-01, -4.7355e-01,  2.5889e-01, -1.3260e+00,  1.5851e+00,\n",
              "         -3.8618e-01,  1.5764e+00, -9.4789e-01, -9.2309e-01,  4.6737e-01,\n",
              "         -4.8595e-01, -2.4293e-02, -5.5705e-01, -3.1455e-01, -1.1338e-01,\n",
              "         -1.6174e-01,  8.3162e-01, -5.6529e-01, -9.5904e-02, -1.1245e-01,\n",
              "         -1.0311e+00, -1.4277e-01, -7.3664e-01,  1.4765e-01, -2.2971e-01,\n",
              "          3.9673e-01, -1.0753e+00,  6.6455e-01,  3.1294e-01, -5.6631e-02,\n",
              "         -3.0951e-01,  2.2493e-01, -1.4850e-01,  2.2910e-01,  2.8938e-01,\n",
              "          6.7629e-01, -9.0940e-01,  4.4851e-01, -3.3832e-01, -3.3420e-01,\n",
              "          4.6286e-01, -3.9156e-01,  6.4487e-01,  3.9093e-01, -1.6771e-02,\n",
              "          9.6232e-01, -1.1312e+00, -4.0280e-01,  1.8588e-01,  2.6001e-01,\n",
              "          9.2113e-01, -2.7153e-01,  8.0074e-01,  2.8548e-01,  1.1330e+00,\n",
              "         -3.1117e-01, -4.8690e-01, -1.0499e+00,  9.8598e-03, -2.8706e-01,\n",
              "         -3.9961e-01, -8.8232e-01,  3.5943e-01, -7.9205e-01, -6.9823e-01,\n",
              "          6.5981e-01,  5.9179e-01, -3.4009e-01,  3.5631e-01, -9.0518e-02,\n",
              "          5.4404e-02,  5.2091e-01, -1.1772e-01, -2.1404e-02,  2.3441e-02,\n",
              "          1.0091e-01,  5.8143e-01, -9.0742e-01,  1.0502e+00,  7.0596e-02,\n",
              "          4.2021e-01, -4.0573e-01,  3.3023e-02,  5.4977e-01, -2.1155e-01,\n",
              "         -2.8467e-01, -2.1110e-01, -6.6788e-01,  3.9122e-01,  2.0167e-01,\n",
              "          3.2140e-01, -5.3764e-01, -6.4544e-02, -4.9503e-01,  1.2885e-01,\n",
              "          2.2294e-01, -1.6210e-01, -5.9338e-01,  8.6498e-01, -8.4388e-01,\n",
              "         -1.7239e-01,  5.8500e-01,  1.3635e+00, -1.5760e-01, -1.6470e-01,\n",
              "         -1.9212e+00,  4.5632e-01,  6.5662e-01,  3.0252e-01, -8.3669e-02,\n",
              "          1.1162e-01,  5.1380e-01,  7.7562e-01, -1.0398e+00,  1.4494e-01,\n",
              "          4.0355e-01,  2.7488e-01, -1.0001e-01, -4.9586e-01,  3.2831e-01,\n",
              "         -1.6557e-01,  2.4734e-02,  9.4796e-01,  6.5025e-01, -1.1657e+00,\n",
              "          9.7131e-01,  5.8161e-01, -1.2391e+00,  1.8583e-01,  9.6496e-01,\n",
              "         -6.7188e-01, -1.7395e-01, -4.7076e-01, -6.9996e-01, -3.6292e-02,\n",
              "          3.2326e-01,  6.5279e-01,  1.5857e-01, -3.8178e-01, -7.6021e-01,\n",
              "         -1.9283e-02,  6.0273e-01, -8.0231e-01,  3.0534e-01,  7.2340e-01,\n",
              "         -4.5853e-01,  8.5664e-01, -1.2392e+00, -2.1578e-01,  1.8629e-01,\n",
              "          5.8645e-01,  1.1212e-01, -8.2547e-01,  4.9638e-01,  1.1431e-01,\n",
              "         -6.6946e-01,  1.9746e-02,  6.7667e-01, -8.0185e-02, -8.2178e-02,\n",
              "          5.1118e-01, -4.2190e-01, -2.7063e-01,  6.8726e-01,  4.8040e-01,\n",
              "          4.6528e-01, -8.6009e-01,  4.8235e-01,  4.8802e-01, -1.9158e-01,\n",
              "         -4.9732e-01, -1.7302e-01,  7.3646e-02, -3.0176e-01,  4.4385e-01,\n",
              "         -1.6570e-01, -2.4044e-01, -3.1199e-01,  5.5935e-01,  8.4654e-02,\n",
              "          6.3183e-01, -3.6332e-01, -4.0035e-03,  5.4902e-02,  8.8018e-01,\n",
              "          8.0403e-01, -1.5738e+00,  7.6655e-01,  4.5431e-01,  1.3196e+00,\n",
              "         -2.2543e-01, -6.7367e-02, -5.6315e-01, -7.8337e-01, -5.9928e-01,\n",
              "          9.9388e-01,  4.2677e-01,  1.5565e-01,  1.2991e+00, -1.3823e-01,\n",
              "         -4.7330e-01, -9.6147e-01,  3.7844e-02, -1.2626e+00, -6.3209e-02,\n",
              "         -6.2502e-01, -5.9404e-01, -3.0698e-01, -4.3991e-02,  2.5447e-01,\n",
              "          5.6304e-02,  2.9623e-02, -1.4003e-01, -9.0930e-01,  3.9465e-01,\n",
              "          5.1400e-01,  3.4101e-01,  5.8502e-01,  8.8187e-03,  6.4684e-01,\n",
              "         -1.0679e+00,  1.9261e-01,  6.7560e-01, -1.2556e-01, -8.9373e-01,\n",
              "         -1.7192e-01, -6.2001e-02,  1.9043e-02, -1.3475e-01, -6.1177e-01,\n",
              "          2.7916e-01,  8.0688e-02, -2.0764e-02, -6.6006e-02, -9.8538e-01,\n",
              "          1.0077e+00,  1.2251e+00, -6.9004e-01,  3.8142e-01, -3.4579e-02,\n",
              "         -2.2673e-03,  1.3628e-01, -9.6969e-02, -2.3826e-01, -4.3809e-01,\n",
              "          1.2707e+00, -1.2643e+00, -1.2259e+00,  1.3250e-03,  1.6211e-01,\n",
              "          6.6284e-01, -1.2526e-01, -8.7850e-01, -3.7673e-01, -7.2941e-01,\n",
              "         -1.9985e-01, -3.4584e-01, -2.3764e-01,  2.0929e-01, -8.5265e-01,\n",
              "         -8.6959e-01,  7.3296e-02,  4.8670e-01, -2.1067e-01, -1.0492e+00,\n",
              "          2.7279e-01, -2.7046e-01,  4.3164e-01,  2.1435e-01,  1.9497e-01,\n",
              "         -1.8009e-01, -2.6097e-01, -1.0510e+00, -1.4399e-01, -4.4938e-01,\n",
              "          3.4237e-01, -4.2369e-01, -3.4243e-01,  4.7377e-01,  6.0406e-01,\n",
              "         -2.9574e-01, -5.2437e-01,  5.0023e-01,  7.5045e-01, -1.0506e+00,\n",
              "         -3.8015e-01,  4.2542e-01, -1.3104e-01, -1.1576e+00,  3.5461e-02,\n",
              "         -1.2123e+00,  8.1284e-01,  7.4158e-01, -6.1665e-02, -1.7858e-01,\n",
              "         -2.7233e-01,  1.6723e-01, -7.6189e-01, -4.6897e-02,  2.6138e-01,\n",
              "          2.2514e-01, -5.0467e-01, -7.6334e-02, -5.6870e-01, -5.9954e-01,\n",
              "         -7.1071e-02,  2.5748e-01,  1.3806e+00,  4.7266e-01,  7.3659e-01,\n",
              "         -1.2811e-01, -5.8549e-01, -6.6802e-01,  6.6773e-01, -2.9148e-01,\n",
              "          7.1404e-01, -2.7279e-01, -8.4168e-01,  2.3216e-01,  6.4598e-01,\n",
              "          3.3574e-01, -1.5344e+00, -1.7103e-01, -5.6746e-01, -2.4354e-01,\n",
              "         -8.5056e-01, -8.5886e-01, -2.2118e-01,  6.2552e-01,  2.9925e-01,\n",
              "          1.8296e-01,  6.1234e-01, -7.4984e-01, -3.3012e-01,  3.4227e-01,\n",
              "         -8.3695e-01, -3.7775e-01,  3.6594e-01,  2.3072e-02, -5.3120e-01,\n",
              "          9.7278e-01,  6.3312e-02,  9.7519e-02,  2.1973e-02,  1.7400e-01,\n",
              "          6.5451e-01, -5.9943e-01,  6.2152e-01,  8.3180e-01,  2.4243e-01,\n",
              "         -7.0655e-01,  2.0125e-01,  7.0657e-01, -2.8193e-01, -3.2747e-01,\n",
              "          4.0119e-01,  1.6697e-01,  1.2031e+00,  1.1114e+00,  6.7388e-01,\n",
              "          7.6634e-01, -2.3141e-01, -3.0810e-01, -3.1501e-02, -2.4703e-01,\n",
              "         -1.0457e-01, -2.6844e-02, -4.2274e-01,  1.2233e-01, -5.1854e-01,\n",
              "          3.2959e-01, -1.5013e-01,  3.2572e-01, -1.3740e-01,  3.7476e-01,\n",
              "         -3.8138e-01,  1.1587e-01,  5.0823e-01, -5.0498e-01, -1.6156e-01,\n",
              "          9.2563e-01, -4.4763e-01,  3.5749e-01, -1.3937e+00, -4.6959e-01,\n",
              "         -6.3569e-02,  4.8912e-01,  4.4158e-01, -3.9566e-01, -4.0239e-01,\n",
              "          7.6553e-01, -4.5417e-01,  6.0901e-01, -5.0285e-02, -1.1499e+00,\n",
              "          1.5333e-01, -1.3780e-01, -9.2101e-01, -3.8819e-01,  2.6015e-01,\n",
              "          4.7425e-01,  5.7947e-01, -5.1846e-01, -9.3090e-01,  1.6527e-01,\n",
              "          5.8723e-01,  3.8862e-01, -4.6652e-01,  7.7639e-01, -2.4310e-01,\n",
              "          6.1275e-02,  7.3001e-01, -4.7051e-01, -7.6680e-01, -2.5298e-01,\n",
              "         -8.6387e-01, -7.1005e-01,  6.4419e-01,  6.5554e-01,  3.1619e-01,\n",
              "          4.3090e-01,  1.9270e-01,  4.8640e-01,  3.2848e-01, -1.4970e-01,\n",
              "          1.0152e+00,  5.7544e-01,  6.1238e-01,  5.0055e-01, -3.4704e-01,\n",
              "         -8.8650e-01,  5.2076e-01, -5.7141e-01,  3.0447e-01, -6.1227e-01,\n",
              "          6.7366e-02,  1.1126e-01, -6.1991e-01, -7.5090e-01, -7.0721e-01,\n",
              "          4.9020e-02, -4.2849e-02, -7.3886e-01,  5.8957e-02,  2.0284e-01,\n",
              "          1.8277e-01, -3.4661e-01, -4.1227e-01, -3.4070e-01,  6.9573e-01,\n",
              "         -1.4571e-01, -7.2461e-01, -8.1861e-01, -4.3171e-01, -2.9195e-01,\n",
              "         -1.0024e+00, -1.7059e-01,  1.2326e-01,  1.5297e-01,  2.3317e-01,\n",
              "          1.3112e+00, -5.6125e-01, -8.0447e-02,  6.6030e-02,  6.3616e-01,\n",
              "          1.0764e+00, -3.7552e-01, -1.9723e-01, -1.2639e-01, -9.7839e-01,\n",
              "          7.1431e-01, -8.5014e-01,  5.3042e-02, -2.2865e-01, -7.5399e-02,\n",
              "          8.2278e-02, -1.7042e-01, -8.3766e-02]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}